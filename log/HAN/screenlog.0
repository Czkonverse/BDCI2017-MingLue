dyhu@mit116:~/BDCI2017-MingLue/log/HAN-11-28-13:20$ [Kdyhu@mit116:~/BDCI2017-MingLue/log/HAN-11-28-13:20$ cd ..
dyhu@mit116:~/BDCI2017-MingLue/log$ ce [K[K[Kcd ..
dyhu@mit116:~/BDCI2017-MingLue$ CUDA_VISBLE[K[K[KIBLE_DEVICES = 0[K[K[K[K-[K=0 pythonr r[Ktrain.py --model-id 4[1P
Using TensorFlow backend.
loading data...
max sentence length:  42583
total vocab size 691360
load word2index
0 1
(120000, 30, 50)
data loaded
config vocab size: 194170
loss weight: 
 0.7786
 0.8593
 1.1661
 1.2979
 1.1405
 0.9833
 0.5955
 1.1791
[torch.FloatTensor of size 8]

training...
lr: 0.001 lr2: 0.0
^[[A[1,    46] loss: 1.949, acc: 25.781
^CProcess Process-2:
Process Process-4:
Process Process-3:
Process Process-1:
Traceback (most recent call last):
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 342, in get
    with self._rlock:
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/synchronize.py", line 96, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 342, in get
    with self._rlock:
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/synchronize.py", line 96, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 342, in get
    with self._rlock:
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/synchronize.py", line 96, in __enter__
    return self._semlock.__enter__()
Traceback (most recent call last):
KeyboardInterrupt
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 343, in get
    res = self._reader.recv_bytes()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "train.py", line 214, in <module>
    main(args.model_id, use_element, args.is_save)
  File "train.py", line 152, in main
    loss.backward()
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/autograd/variable.py", line 156, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/autograd/__init__.py", line 98, in backward
    variables, grad_variables, retain_graph)
KeyboardInterrupt
dyhu@mit116:~/BDCI2017-MingLue$ vlrw[K[K[K[Kclear
[H[Jdyhu@mit116:~/BDCI2017-MingLue$ clearCUDA_VISIBLE_DEVICES=0 python train.py --model-id 4[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ccd ..[K[1Pexitcd ..CUDA_VISIBLE_DEVICES=0 python train.py --model-id 4
Using TensorFlow backend.
loading data...
max sentence length:  42583
total vocab size 691360
load word2index
0 1
(120000, 40, 60)
data loaded
config vocab size: 194170
loss weight: 
 0.7786
 0.8593
 1.1661
 1.2979
 1.1405
 0.9833
 0.5955
 1.1791
[torch.FloatTensor of size 8]

training...
lr: 0.001 lr2: 0.0
[1,    46] loss: 1.956, acc: 15.625
[1,    92] loss: 1.902, acc: 23.438
[1,   138] loss: 1.847, acc: 32.812
[1,   184] loss: 1.798, acc: 28.125
[1,   230] loss: 1.768, acc: 35.938
[1,   276] loss: 1.731, acc: 29.688
[1,   322] loss: 1.710, acc: 31.250
[1,   368] loss: 1.668, acc: 39.062
[1,   414] loss: 1.683, acc: 35.938
[1,   460] loss: 1.683, acc: 29.688
[1,   506] loss: 1.646, acc: 32.812
[1,   552] loss: 1.626, acc: 35.938
[1,   598] loss: 1.618, acc: 32.812
[1,   644] loss: 1.611, acc: 34.375
[1,   690] loss: 1.628, acc: 37.500
[1,   736] loss: 1.637, acc: 34.375
[1,   782] loss: 1.606, acc: 42.188
[1,   828] loss: 1.600, acc: 42.188
[1,   874] loss: 1.583, acc: 54.688
[1,   920] loss: 1.593, acc: 31.250
[1,   966] loss: 1.560, acc: 45.312
[1,  1012] loss: 1.554, acc: 42.188
[1,  1058] loss: 1.569, acc: 46.875
[1,  1104] loss: 1.541, acc: 31.250
[1,  1150] loss: 1.557, acc: 40.625
[1,  1196] loss: 1.565, acc: 45.312
[1,  1242] loss: 1.553, acc: 37.500
[1,  1288] loss: 1.524, acc: 35.938
[1,  1334] loss: 1.530, acc: 37.500
[1,  1380] loss: 1.531, acc: 46.875
[1,  1426] loss: 1.519, acc: 34.375
[1,  1472] loss: 1.512, acc: 50.000
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[2, 0, 5, 0, 1, 5, 2, 1, 4, 2]
Acc: 42.7
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.4124896170825468
lr: 0.001 lr2: 0.0
[2,    46] loss: 1.452, acc: 39.062
[2,    92] loss: 1.445, acc: 54.688
[2,   138] loss: 1.451, acc: 46.875
[2,   184] loss: 1.441, acc: 53.125
[2,   230] loss: 1.438, acc: 56.250
[2,   276] loss: 1.443, acc: 42.188
[2,   322] loss: 1.433, acc: 40.625
[2,   368] loss: 1.430, acc: 54.688
[2,   414] loss: 1.432, acc: 43.750
[2,   460] loss: 1.433, acc: 43.750
[2,   506] loss: 1.424, acc: 51.562
[2,   552] loss: 1.424, acc: 50.000
[2,   598] loss: 1.425, acc: 43.750
[2,   644] loss: 1.437, acc: 56.250
[2,   690] loss: 1.422, acc: 46.875
[2,   736] loss: 1.414, acc: 45.312
[2,   782] loss: 1.378, acc: 48.438
[2,   828] loss: 1.430, acc: 53.125
[2,   874] loss: 1.434, acc: 45.312
[2,   920] loss: 1.410, acc: 45.312
[2,   966] loss: 1.381, acc: 50.000
[2,  1012] loss: 1.411, acc: 48.438
[2,  1058] loss: 1.415, acc: 32.812
[2,  1104] loss: 1.384, acc: 51.562
[2,  1150] loss: 1.409, acc: 48.438
[2,  1196] loss: 1.395, acc: 53.125
[2,  1242] loss: 1.404, acc: 46.875
[2,  1288] loss: 1.409, acc: 45.312
[2,  1334] loss: 1.391, acc: 54.688
[2,  1380] loss: 1.395, acc: 48.438
[2,  1426] loss: 1.399, acc: 50.000
[2,  1472] loss: 1.394, acc: 48.438
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 0, 5, 0, 1, 6, 4, 1, 4, 1]
Acc: 44.8375
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.44757881154799234
lr: 0.00075 lr2: 0.0
[3,    46] loss: 1.256, acc: 57.812
[3,    92] loss: 1.263, acc: 42.188
[3,   138] loss: 1.248, acc: 59.375
[3,   184] loss: 1.244, acc: 54.688
[3,   230] loss: 1.265, acc: 60.938
[3,   276] loss: 1.258, acc: 53.125
[3,   322] loss: 1.235, acc: 62.500
[3,   368] loss: 1.232, acc: 46.875
[3,   414] loss: 1.258, acc: 48.438
[3,   460] loss: 1.257, acc: 56.250
[3,   506] loss: 1.215, acc: 51.562
[3,   552] loss: 1.227, acc: 51.562
[3,   598] loss: 1.243, acc: 53.125
[3,   644] loss: 1.239, acc: 51.562
[3,   690] loss: 1.262, acc: 51.562
[3,   736] loss: 1.255, acc: 46.875
[3,   782] loss: 1.251, acc: 57.812
[3,   828] loss: 1.255, acc: 60.938
[3,   874] loss: 1.268, acc: 53.125
[3,   920] loss: 1.223, acc: 59.375
[3,   966] loss: 1.235, acc: 57.812
[3,  1012] loss: 1.222, acc: 54.688
[3,  1058] loss: 1.198, acc: 50.000
[3,  1104] loss: 1.260, acc: 56.250
[3,  1150] loss: 1.240, acc: 50.000
[3,  1196] loss: 1.242, acc: 45.312
[3,  1242] loss: 1.253, acc: 51.562
[3,  1288] loss: 1.228, acc: 48.438
[3,  1334] loss: 1.285, acc: 57.812
[3,  1380] loss: 1.236, acc: 46.875
[3,  1426] loss: 1.261, acc: 56.250
[3,  1472] loss: 1.231, acc: 53.125
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 0, 4, 0, 0, 5, 4, 1, 4, 2]
Acc: 42.9333333333
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.4375076935404251
lr: 0.0005625000000000001 lr2: 0.0002
[4,    46] loss: 1.128, acc: 67.188
[4,    92] loss: 1.109, acc: 54.688
[4,   138] loss: 1.081, acc: 57.812
[4,   184] loss: 1.083, acc: 53.125
[4,   230] loss: 1.088, acc: 56.250
[4,   276] loss: 1.075, acc: 60.938
[4,   322] loss: 1.098, acc: 76.562
[4,   368] loss: 1.117, acc: 57.812
[4,   414] loss: 1.124, acc: 59.375
[4,   460] loss: 1.127, acc: 53.125
[4,   506] loss: 1.090, acc: 57.812
[4,   552] loss: 1.065, acc: 54.688
[4,   598] loss: 1.067, acc: 57.812
[4,   644] loss: 1.093, acc: 59.375
[4,   690] loss: 1.089, acc: 60.938
[4,   736] loss: 1.100, acc: 59.375
^[[A^[[A^[[A            [4,   782] loss: 1.064, acc: 67.188
[4,   828] loss: 1.068, acc: 62.500
[4,   874] loss: 1.120, acc: 59.375
[4,   920] loss: 1.097, acc: 67.188
[4,   966] loss: 1.128, acc: 53.125
[4,  1012] loss: 1.135, acc: 48.438
[4,  1058] loss: 1.078, acc: 59.375
[4,  1104] loss: 1.108, acc: 56.250
[4,  1150] loss: 1.104, acc: 56.250
[4,  1196] loss: 1.107, acc: 57.812
[4,  1242] loss: 1.097, acc: 59.375
[4,  1288] loss: 1.109, acc: 59.375
[4,  1334] loss: 1.099, acc: 57.812
[4,  1380] loss: 1.099, acc: 57.812
[4,  1426] loss: 1.079, acc: 64.062
[4,  1472] loss: 1.106, acc: 65.625
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 0, 4, 0, 1, 5, 4, 1, 4, 1]
Acc: 42.2333333333
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.435595395686952
avg_loss_weight: 
 0.5014
 0.6219
 0.6509
 0.8536
 0.6265
 0.5841
 0.4500
 0.8973
[torch.FloatTensor of size 8]

lr: 0.00042187500000000005 lr2: 0.00015000000000000001
[5,    46] loss: 0.945, acc: 70.312
[5,    92] loss: 0.950, acc: 68.750
[5,   138] loss: 0.960, acc: 57.812
[5,   184] loss: 0.961, acc: 60.938
[5,   230] loss: 0.945, acc: 56.250
[5,   276] loss: 0.934, acc: 76.562
[5,   322] loss: 0.923, acc: 70.312
[5,   368] loss: 0.934, acc: 67.188
[5,   414] loss: 0.957, acc: 59.375
[5,   460] loss: 0.955, acc: 56.250
[5,   506] loss: 0.978, acc: 62.500
[5,   552] loss: 0.932, acc: 62.500
[5,   598] loss: 0.966, acc: 64.062
[5,   644] loss: 0.946, acc: 59.375
[5,   690] loss: 0.962, acc: 73.438
[5,   736] loss: 0.960, acc: 59.375
[5,   782] loss: 0.944, acc: 67.188
[5,   828] loss: 0.954, acc: 65.625
[5,   874] loss: 0.961, acc: 65.625
[5,   920] loss: 0.931, acc: 60.938
[5,   966] loss: 0.946, acc: 65.625
[5,  1012] loss: 0.972, acc: 60.938
[5,  1058] loss: 0.977, acc: 68.750
[5,  1104] loss: 0.948, acc: 67.188
[5,  1150] loss: 0.981, acc: 59.375
[5,  1196] loss: 0.990, acc: 64.062
[5,  1242] loss: 0.956, acc: 65.625
[5,  1288] loss: 0.959, acc: 62.500
[5,  1334] loss: 0.991, acc: 68.750
[5,  1380] loss: 0.948, acc: 71.875
[5,  1426] loss: 0.967, acc: 56.250
[5,  1472] loss: 0.974, acc: 65.625
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 1, 5, 0, 1, 6, 4, 1, 4, 1]
Acc: 42.625
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.4362264447303153
avg_loss_weight: 
 0.5504
 0.6147
 0.6474
 0.8299
 0.6752
 0.5804
 0.4093
 0.8616
[torch.FloatTensor of size 8]

lr: 0.00031640625000000006 lr2: 0.00011250000000000001
[6,    46] loss: 0.799, acc: 79.688
[6,    92] loss: 0.822, acc: 71.875
[6,   138] loss: 0.813, acc: 78.125
[6,   184] loss: 0.810, acc: 65.625
[6,   230] loss: 0.807, acc: 76.562
[6,   276] loss: 0.848, acc: 70.312
[6,   322] loss: 0.825, acc: 65.625
[6,   368] loss: 0.835, acc: 59.375
[6,   414] loss: 0.861, acc: 67.188
[6,   460] loss: 0.824, acc: 68.750
[6,   506] loss: 0.851, acc: 68.750
[6,   552] loss: 0.836, acc: 67.188
[6,   598] loss: 0.841, acc: 76.562
[6,   644] loss: 0.856, acc: 73.438
[6,   690] loss: 0.801, acc: 62.500
[6,   736] loss: 0.842, acc: 75.000
[6,   782] loss: 0.830, acc: 62.500
[6,   828] loss: 0.794, acc: 70.312
[6,   874] loss: 0.836, acc: 68.750
[6,   920] loss: 0.854, acc: 75.000
[6,   966] loss: 0.823, acc: 81.250
[6,  1012] loss: 0.820, acc: 78.125
[6,  1058] loss: 0.837, acc: 68.750
[6,  1104] loss: 0.795, acc: 73.438
[6,  1150] loss: 0.824, acc: 65.625
[6,  1196] loss: 0.872, acc: 73.438
[6,  1242] loss: 0.870, acc: 60.938
[6,  1288] loss: 0.806, acc: 70.312
[6,  1334] loss: 0.845, acc: 68.750
[6,  1380] loss: 0.845, acc: 62.500
[6,  1426] loss: 0.841, acc: 62.500
[6,  1472] loss: 0.843, acc: 81.250
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 0, 5, 0, 1, 6, 4, 1, 4, 1]
Acc: 41.8333333333
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.4315441584562104
avg_loss_weight: 
 0.5505
 0.6083
 0.6547
 0.8327
 0.6650
 0.5927
 0.4141
 0.8690
[torch.FloatTensor of size 8]

lr: 0.00023730468750000005 lr2: 8.4375e-05
[7,    46] loss: 0.731, acc: 75.000
[7,    92] loss: 0.694, acc: 79.688
[7,   138] loss: 0.694, acc: 78.125
[7,   184] loss: 0.715, acc: 65.625
[7,   230] loss: 0.716, acc: 92.188
[7,   276] loss: 0.699, acc: 75.000
[7,   322] loss: 0.735, acc: 73.438
[7,   368] loss: 0.731, acc: 71.875
[7,   414] loss: 0.734, acc: 78.125
[7,   460] loss: 0.718, acc: 65.625
[7,   506] loss: 0.718, acc: 81.250
[7,   552] loss: 0.737, acc: 70.312
[7,   598] loss: 0.695, acc: 82.812
[7,   644] loss: 0.717, acc: 89.062
[7,   690] loss: 0.702, acc: 81.250
[7,   736] loss: 0.700, acc: 84.375
[7,   782] loss: 0.726, acc: 75.000
[7,   828] loss: 0.701, acc: 76.562
[7,   874] loss: 0.720, acc: 75.000
[7,   920] loss: 0.692, acc: 78.125
[7,   966] loss: 0.740, acc: 79.688
[7,  1012] loss: 0.732, acc: 89.062
[7,  1058] loss: 0.727, acc: 65.625
[7,  1104] loss: 0.771, acc: 76.562
[7,  1150] loss: 0.727, acc: 70.312
[7,  1196] loss: 0.716, acc: 75.000
[7,  1242] loss: 0.745, acc: 81.250
[7,  1288] loss: 0.723, acc: 87.500
[7,  1334] loss: 0.765, acc: 65.625
[7,  1380] loss: 0.740, acc: 78.125
[7,  1426] loss: 0.722, acc: 79.688
[7,  1472] loss: 0.712, acc: 78.125
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 1, 5, 0, 1, 6, 4, 1, 4, 1]
Acc: 42.1458333333
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.43170510453767497
avg_loss_weight: 
 0.5485
 0.6137
 0.6600
 0.8269
 0.6710
 0.5961
 0.4054
 0.8739
[torch.FloatTensor of size 8]

lr: 0.00017797851562500002 lr2: 6.328125e-05
[8,    46] loss: 0.596, acc: 75.000
[8,    92] loss: 0.634, acc: 81.250
[8,   138] loss: 0.625, acc: 79.688
[8,   184] loss: 0.618, acc: 81.250
[8,   230] loss: 0.645, acc: 75.000
[8,   276] loss: 0.630, acc: 71.875
[8,   322] loss: 0.621, acc: 85.938
[8,   368] loss: 0.594, acc: 79.688
[8,   414] loss: 0.640, acc: 75.000
[8,   460] loss: 0.643, acc: 79.688
[8,   506] loss: 0.667, acc: 81.250
[8,   552] loss: 0.614, acc: 75.000
[8,   598] loss: 0.630, acc: 85.938
[8,   644] loss: 0.601, acc: 82.812
[8,   690] loss: 0.652, acc: 82.812
[8,   736] loss: 0.654, acc: 82.812
[8,   782] loss: 0.634, acc: 81.250
[8,   828] loss: 0.616, acc: 85.938
[8,   874] loss: 0.669, acc: 79.688
[8,   920] loss: 0.628, acc: 82.812
[8,   966] loss: 0.650, acc: 79.688
[8,  1012] loss: 0.636, acc: 79.688
[8,  1058] loss: 0.642, acc: 82.812
[8,  1104] loss: 0.623, acc: 85.938
[8,  1150] loss: 0.637, acc: 78.125
[8,  1196] loss: 0.636, acc: 78.125
[8,  1242] loss: 0.637, acc: 76.562
[8,  1288] loss: 0.637, acc: 81.250
[8,  1334] loss: 0.624, acc: 85.938
[8,  1380] loss: 0.609, acc: 79.688
[8,  1426] loss: 0.658, acc: 75.000
[8,  1472] loss: 0.628, acc: 71.875
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 1, 5, 0, 1, 6, 4, 1, 4, 1]
Acc: 41.5416666667
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.42768084314276983
avg_loss_weight: 
 0.5493
 0.6174
 0.6570
 0.8211
 0.6782
 0.6007
 0.4041
 0.8723
[torch.FloatTensor of size 8]

lr: 0.00013348388671875002 lr2: 4.74609375e-05
[9,    46] loss: 0.562, acc: 76.562
[9,    92] loss: 0.537, acc: 84.375
[9,   138] loss: 0.529, acc: 79.688
[9,   184] loss: 0.559, acc: 87.500
[9,   230] loss: 0.562, acc: 90.625
[9,   276] loss: 0.512, acc: 85.938
[9,   322] loss: 0.523, acc: 85.938
[9,   368] loss: 0.583, acc: 87.500
[9,   414] loss: 0.553, acc: 82.812
[9,   460] loss: 0.550, acc: 84.375
[9,   506] loss: 0.589, acc: 87.500
[9,   552] loss: 0.576, acc: 90.625
[9,   598] loss: 0.549, acc: 84.375
[9,   644] loss: 0.564, acc: 84.375
[9,   690] loss: 0.528, acc: 87.500
[9,   736] loss: 0.564, acc: 79.688
[9,   782] loss: 0.608, acc: 75.000
[9,   828] loss: 0.558, acc: 76.562
[9,   874] loss: 0.575, acc: 78.125
[9,   920] loss: 0.574, acc: 82.812
[9,   966] loss: 0.541, acc: 85.938
[9,  1012] loss: 0.580, acc: 89.062
[9,  1058] loss: 0.534, acc: 84.375
[9,  1104] loss: 0.576, acc: 92.188
[9,  1150] loss: 0.557, acc: 70.312
[9,  1196] loss: 0.583, acc: 84.375
[9,  1242] loss: 0.569, acc: 82.812
[9,  1288] loss: 0.564, acc: 81.250
[9,  1334] loss: 0.572, acc: 84.375
[9,  1380] loss: 0.570, acc: 79.688
[9,  1426] loss: 0.585, acc: 85.938
[9,  1472] loss: 0.592, acc: 85.938
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 1, 5, 0, 1, 6, 4, 1, 4, 1]
Acc: 41.7916666667
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.42871278404948837
avg_loss_weight: 
 0.5455
 0.6220
 0.6577
 0.8192
 0.6824
 0.6013
 0.4024
 0.8720
[torch.FloatTensor of size 8]

lr: 0.00010011291503906251 lr2: 3.5595703124999996e-05
[10,    46] loss: 0.501, acc: 82.812
[10,    92] loss: 0.539, acc: 82.812
[10,   138] loss: 0.481, acc: 76.562
[10,   184] loss: 0.508, acc: 85.938
[10,   230] loss: 0.509, acc: 82.812
[10,   276] loss: 0.507, acc: 85.938
[10,   322] loss: 0.491, acc: 82.812
[10,   368] loss: 0.517, acc: 73.438
[10,   414] loss: 0.507, acc: 82.812
[10,   460] loss: 0.492, acc: 89.062
[10,   506] loss: 0.509, acc: 87.500
[10,   552] loss: 0.506, acc: 79.688
[10,   598] loss: 0.465, acc: 87.500
[10,   644] loss: 0.495, acc: 79.688
[10,   690] loss: 0.534, acc: 92.188
[10,   736] loss: 0.488, acc: 84.375
[10,   782] loss: 0.481, acc: 87.500
[10,   828] loss: 0.517, acc: 73.438
[10,   874] loss: 0.524, acc: 84.375
[10,   920] loss: 0.483, acc: 82.812
[10,   966] loss: 0.542, acc: 81.250
[10,  1012] loss: 0.523, acc: 87.500
[10,  1058] loss: 0.484, acc: 84.375
[10,  1104] loss: 0.479, acc: 79.688
[10,  1150] loss: 0.523, acc: 81.250
[10,  1196] loss: 0.538, acc: 84.375
[10,  1242] loss: 0.527, acc: 89.062
[10,  1288] loss: 0.515, acc: 82.812
[10,  1334] loss: 0.515, acc: 82.812
[10,  1380] loss: 0.496, acc: 89.062
[10,  1426] loss: 0.504, acc: 84.375
[10,  1472] loss: 0.540, acc: 79.688
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 1, 3, 0, 1, 6, 4, 1, 4, 1]
Acc: 41.5916666667
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.42694469336587104
avg_loss_weight: 
 0.5446
 0.6231
 0.6590
 0.8173
 0.6848
 0.6030
 0.4021
 0.8718
[torch.FloatTensor of size 8]

lr: 7.508468627929689e-05 lr2: 2.6696777343749997e-05
[11,    46] loss: 0.455, acc: 89.062
[11,    92] loss: 0.471, acc: 84.375
[11,   138] loss: 0.451, acc: 81.250
[11,   184] loss: 0.444, acc: 89.062
[11,   230] loss: 0.438, acc: 89.062
[11,   276] loss: 0.468, acc: 92.188
[11,   322] loss: 0.452, acc: 84.375
[11,   368] loss: 0.458, acc: 84.375
[11,   414] loss: 0.470, acc: 84.375
[11,   460] loss: 0.453, acc: 90.625
[11,   506] loss: 0.461, acc: 75.000
[11,   552] loss: 0.455, acc: 84.375
[11,   598] loss: 0.487, acc: 85.938
[11,   644] loss: 0.497, acc: 85.938
[11,   690] loss: 0.460, acc: 87.500
[11,   736] loss: 0.461, acc: 85.938
[11,   782] loss: 0.489, acc: 78.125
[11,   828] loss: 0.481, acc: 81.250
[11,   874] loss: 0.456, acc: 89.062
[11,   920] loss: 0.449, acc: 92.188
[11,   966] loss: 0.461, acc: 82.812
[11,  1012] loss: 0.471, acc: 90.625
[11,  1058] loss: 0.495, acc: 84.375
[11,  1104] loss: 0.479, acc: 89.062
[11,  1150] loss: 0.461, acc: 81.250
[11,  1196] loss: 0.482, acc: 81.250
[11,  1242] loss: 0.488, acc: 89.062
[11,  1288] loss: 0.436, acc: 89.062
[11,  1334] loss: 0.468, acc: 89.062
[11,  1380] loss: 0.450, acc: 84.375
[11,  1426] loss: 0.480, acc: 76.562
[11,  1472] loss: 0.481, acc: 89.062
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 1, 3, 0, 1, 6, 4, 1, 4, 1]
Acc: 41.4833333333
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.425532290315245
avg_loss_weight: 
 0.5467
 0.6245
 0.6603
 0.8148
 0.6887
 0.6036
 0.4001
 0.8722
[torch.FloatTensor of size 8]

lr: 5.631351470947266e-05 lr2: 2.0022583007812497e-05
[12,    46] loss: 0.421, acc: 89.062
[12,    92] loss: 0.413, acc: 90.625
[12,   138] loss: 0.422, acc: 89.062
[12,   184] loss: 0.435, acc: 85.938
[12,   230] loss: 0.415, acc: 90.625
[12,   276] loss: 0.434, acc: 89.062
[12,   322] loss: 0.444, acc: 82.812
[12,   368] loss: 0.443, acc: 87.500
[12,   414] loss: 0.429, acc: 87.500
[12,   460] loss: 0.430, acc: 90.625
[12,   506] loss: 0.422, acc: 85.938
[12,   552] loss: 0.411, acc: 85.938
[12,   598] loss: 0.435, acc: 90.625
[12,   644] loss: 0.441, acc: 92.188
[12,   690] loss: 0.453, acc: 76.562
[12,   736] loss: 0.460, acc: 87.500
[12,   782] loss: 0.437, acc: 87.500
[12,   828] loss: 0.426, acc: 84.375
[12,   874] loss: 0.425, acc: 92.188
[12,   920] loss: 0.416, acc: 90.625
[12,   966] loss: 0.417, acc: 78.125
[12,  1012] loss: 0.417, acc: 90.625
[12,  1058] loss: 0.451, acc: 84.375
[12,  1104] loss: 0.455, acc: 84.375
^[:[12,  1150] loss: 0.410, acc: 84.375
^CProcess Process-91:
Process Process-89:
Process Process-90:
Process Process-92:
Traceback (most recent call last):
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 342, in get
    with self._rlock:
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/synchronize.py", line 96, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 343, in get
    res = self._reader.recv_bytes()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 342, in get
    with self._rlock:
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 342, in get
    with self._rlock:
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/synchronize.py", line 96, in __enter__
    return self._semlock.__enter__()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/synchronize.py", line 96, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
  File "train.py", line 214, in <module>
    main(args.model_id, use_element, args.is_save)
  File "train.py", line 152, in main
    loss.backward()
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/autograd/variable.py", line 156, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/autograd/__init__.py", line 98, in backward
    variables, grad_variables, retain_graph)
KeyboardInterrupt
dyhu@mit116:~/BDCI2017-MingLue$ clear
[H[Jdyhu@mit116:~/BDCI2017-MingLue$ clearCUDA_VISIBLE_DEVICES=0 python train.py --model-id 4[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cclear[KCUDA_VISIBLE_DEVICES=0 python train.py --model-id 4
Using TensorFlow backend.
loading data...
max sentence length:  42583
total vocab size 691360
load word2index
0 1
(120000, 40, 60)
data loaded
config vocab size: 194170
pretrain...
loss weight: 
 0.7786
 0.8593
 1.1661
 1.2979
 1.1405
 0.9833
 0.5955
 1.1791
[torch.FloatTensor of size 8]

Traceback (most recent call last):
  File "train.py", line 214, in <module>
    main(args.model_id, use_element, args.is_save)
  File "train.py", line 114, in main
    config.weight_decay)
  File "/home/dyhu/BDCI2017-MingLue/models/hierarchical.py", line 275, in get_optimizer
    {'params': self.word_to_sentence.word_context.parameters()},
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/autograd/variable.py", line 65, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'Parameter' object has no attribute 'parameters'
dyhu@mit116:~/BDCI2017-MingLue$ CUDA_VISIBLE_DEVICES=0 python train.py --model-id 4[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cclear[KCUDA_VISIBLE_DEVICES=0 python train.py --model-id 4[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cclear[KCUDA_VISIBLE_DEVICES=0 python train.py --model-id 4[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ccd ..[K[1PexitCUDA_VISIBLE_DEVICES=0 python train.py --model-id 454[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cexit[Kcd ..CUDA_VISIBLE_DEVICES=0 python train.py --model-id 4[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cclear[KCUDA_VISIBLE_DEVICES=0 python train.py --model-id 4[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cclear[KCUDA_VISIBLE_DEVICES=0 python train.py --model-id 4[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[Kcd ..[1PexitCUDA_VISIBLE_DEVICES=0 python train.py --model-id 45[C[K4[1P[1@3
Using TensorFlow backend.
loading data...
max sentence length:  42583
total vocab size 691360
load word2index
0 1
(120000, 40, 60)
data loaded
config vocab size: 194170
pretrain...
loss weight: 
 0.7786
 0.8593
 1.1661
 1.2979
 1.1405
 0.9833
 0.5955
 1.1791
[torch.FloatTensor of size 8]

training...
lr: 0.001 lr2: 0.0
[1,    46] loss: 1.969, acc: 23.438
[1,    92] loss: 1.903, acc: 28.125
[1,   138] loss: 1.857, acc: 40.625
[1,   184] loss: 1.769, acc: 21.875
[1,   230] loss: 1.748, acc: 37.500
[1,   276] loss: 1.728, acc: 34.375
[1,   322] loss: 1.729, acc: 40.625
[1,   368] loss: 1.697, acc: 35.938
[1,   414] loss: 1.702, acc: 31.250
[1,   460] loss: 1.699, acc: 34.375
[1,   506] loss: 1.672, acc: 29.688
[1,   552] loss: 1.671, acc: 42.188
[1,   598] loss: 1.652, acc: 37.500
[1,   644] loss: 1.666, acc: 31.250
[1,   690] loss: 1.665, acc: 39.062
[1,   736] loss: 1.634, acc: 28.125
[1,   782] loss: 1.641, acc: 39.062
[1,   828] loss: 1.661, acc: 35.938
[1,   874] loss: 1.646, acc: 39.062
[1,   920] loss: 1.626, acc: 35.938
[1,   966] loss: 1.639, acc: 35.938
[1,  1012] loss: 1.622, acc: 26.562
[1,  1058] loss: 1.636, acc: 45.312
[1,  1104] loss: 1.616, acc: 29.688
[1,  1150] loss: 1.613, acc: 25.000
[1,  1196] loss: 1.610, acc: 29.688
[1,  1242] loss: 1.610, acc: 34.375
[1,  1288] loss: 1.578, acc: 37.500
[1,  1334] loss: 1.596, acc: 35.938
[1,  1380] loss: 1.611, acc: 29.688
[1,  1426] loss: 1.591, acc: 45.312
[1,  1472] loss: 1.567, acc: 34.375
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[5, 1, 5, 1, 1, 5, 1, 2, 5, 1]
Acc: 40.6625
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.3889038124730385
lr: 0.001 lr2: 0.0
[2,    46] loss: 1.563, acc: 39.062
[2,    92] loss: 1.576, acc: 29.688
[2,   138] loss: 1.560, acc: 46.875
[2,   184] loss: 1.559, acc: 40.625
[2,   230] loss: 1.552, acc: 42.188
[2,   276] loss: 1.557, acc: 43.750
[2,   322] loss: 1.563, acc: 42.188
[2,   368] loss: 1.557, acc: 40.625
[2,   414] loss: 1.535, acc: 35.938
[2,   460] loss: 1.545, acc: 40.625
[2,   506] loss: 1.531, acc: 31.250
[2,   552] loss: 1.541, acc: 46.875
[2,   598] loss: 1.520, acc: 35.938
[2,   644] loss: 1.540, acc: 51.562
[2,   690] loss: 1.527, acc: 45.312
[2,   736] loss: 1.550, acc: 37.500
[2,   782] loss: 1.525, acc: 28.125
[2,   828] loss: 1.517, acc: 29.688
[2,   874] loss: 1.527, acc: 32.812
[2,   920] loss: 1.508, acc: 40.625
[2,   966] loss: 1.521, acc: 42.188
[2,  1012] loss: 1.516, acc: 45.312
[2,  1058] loss: 1.532, acc: 34.375
[2,  1104] loss: 1.496, acc: 40.625
[2,  1150] loss: 1.531, acc: 37.500
[2,  1196] loss: 1.506, acc: 46.875
[2,  1242] loss: 1.508, acc: 35.938
[2,  1288] loss: 1.525, acc: 42.188
[2,  1334] loss: 1.502, acc: 53.125
[2,  1380] loss: 1.489, acc: 34.375
[2,  1426] loss: 1.499, acc: 53.125
[2,  1472] loss: 1.495, acc: 46.875
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[5, 2, 5, 0, 2, 5, 2, 2, 5, 2]
Acc: 42.975
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.40891607271426406
lr: 0.00075 lr2: 0.0
[3,    46] loss: 1.488, acc: 51.562
[3,    92] loss: 1.481, acc: 46.875
[3,   138] loss: 1.480, acc: 32.812
[3,   184] loss: 1.465, acc: 45.312
[3,   230] loss: 1.494, acc: 31.250
[3,   276] loss: 1.427, acc: 43.750
[3,   322] loss: 1.480, acc: 34.375
[3,   368] loss: 1.475, acc: 46.875
[3,   414] loss: 1.480, acc: 45.312
[3,   460] loss: 1.479, acc: 39.062
[3,   506] loss: 1.445, acc: 45.312
[3,   552] loss: 1.460, acc: 34.375
[3,   598] loss: 1.456, acc: 42.188
[3,   644] loss: 1.459, acc: 35.938
[3,   690] loss: 1.449, acc: 32.812
[3,   736] loss: 1.430, acc: 50.000
[3,   782] loss: 1.474, acc: 43.750
[3,   828] loss: 1.454, acc: 39.062
[3,   874] loss: 1.470, acc: 43.750
[3,   920] loss: 1.432, acc: 39.062
[3,   966] loss: 1.456, acc: 45.312
[3,  1012] loss: 1.450, acc: 50.000
[3,  1058] loss: 1.471, acc: 31.250
[3,  1104] loss: 1.450, acc: 42.188
[3,  1150] loss: 1.469, acc: 56.250
[3,  1196] loss: 1.456, acc: 45.312
[3,  1242] loss: 1.472, acc: 45.312
[3,  1288] loss: 1.432, acc: 42.188
[3,  1334] loss: 1.430, acc: 39.062
[3,  1380] loss: 1.457, acc: 46.875
[3,  1426] loss: 1.474, acc: 42.188
[3,  1472] loss: 1.453, acc: 48.438
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[5, 2, 5, 0, 2, 5, 2, 2, 4, 2]
Acc: 44.05
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.4251152599803972
lr: 0.0005625000000000001 lr2: 0.0002
[4,    46] loss: 1.437, acc: 54.688
[4,    92] loss: 1.423, acc: 48.438
[4,   138] loss: 1.406, acc: 51.562
[4,   184] loss: 1.423, acc: 40.625
[4,   230] loss: 1.428, acc: 42.188
[4,   276] loss: 1.406, acc: 50.000
[4,   322] loss: 1.424, acc: 48.438
[4,   368] loss: 1.392, acc: 50.000
[4,   414] loss: 1.393, acc: 54.688
[4,   460] loss: 1.420, acc: 53.125
[4,   506] loss: 1.414, acc: 45.312
[4,   552] loss: 1.420, acc: 48.438
[4,   598] loss: 1.408, acc: 45.312
[4,   644] loss: 1.389, acc: 45.312
[4,   690] loss: 1.416, acc: 42.188
[4,   736] loss: 1.406, acc: 43.750
[4,   782] loss: 1.404, acc: 46.875
[4,   828] loss: 1.391, acc: 40.625
[4,   874] loss: 1.378, acc: 56.250
[4,   920] loss: 1.420, acc: 37.500
[4,   966] loss: 1.412, acc: 39.062
[4,  1012] loss: 1.379, acc: 46.875
[4,  1058] loss: 1.389, acc: 56.250
[4,  1104] loss: 1.371, acc: 46.875
[4,  1150] loss: 1.379, acc: 54.688
[4,  1196] loss: 1.354, acc: 39.062
[4,  1242] loss: 1.374, acc: 59.375
[4,  1288] loss: 1.358, acc: 42.188
[4,  1334] loss: 1.382, acc: 51.562
[4,  1380] loss: 1.383, acc: 37.500
[4,  1426] loss: 1.345, acc: 53.125
[4,  1472] loss: 1.383, acc: 56.250
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 2, 5, 0, 4, 5, 2, 1, 4, 2]
Acc: 45.0583333333
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.4465778629990925
avg_loss_weight: 
 0.4863
 0.4943
 0.7736
 0.9231
 0.8176
 0.3604
 0.4059
 0.9018
[torch.FloatTensor of size 8]

lr: 0.00042187500000000005 lr2: 0.00015000000000000001
^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[B[5,    46] loss: 1.314, acc: 60.938
[5,    92] loss: 1.316, acc: 48.438
[5,   138] loss: 1.328, acc: 46.875
[5,   184] loss: 1.312, acc: 54.688
[5,   230] loss: 1.324, acc: 39.062
[5,   276] loss: 1.311, acc: 60.938
[5,   322] loss: 1.335, acc: 51.562
[5,   368] loss: 1.295, acc: 57.812
[5,   414] loss: 1.327, acc: 59.375
[5,   460] loss: 1.323, acc: 42.188
[5,   506] loss: 1.305, acc: 56.250
[5,   552] loss: 1.290, acc: 60.938
[5,   598] loss: 1.332, acc: 45.312
[5,   644] loss: 1.274, acc: 51.562
[5,   690] loss: 1.318, acc: 43.750
[5,   736] loss: 1.287, acc: 57.812
[5,   782] loss: 1.295, acc: 45.312
[5,   828] loss: 1.314, acc: 50.000
[5,   874] loss: 1.308, acc: 62.500
[5,   920] loss: 1.300, acc: 62.500
[5,   966] loss: 1.293, acc: 45.312
[5,  1012] loss: 1.312, acc: 53.125
[5,  1058] loss: 1.311, acc: 51.562
[5,  1104] loss: 1.331, acc: 45.312
[5,  1150] loss: 1.301, acc: 54.688
[5,  1196] loss: 1.300, acc: 42.188
[5,  1242] loss: 1.282, acc: 56.250
[5,  1288] loss: 1.296, acc: 46.875
[5,  1334] loss: 1.307, acc: 43.750
[5,  1380] loss: 1.304, acc: 43.750
[5,  1426] loss: 1.300, acc: 37.500
[5,  1472] loss: 1.270, acc: 60.938
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 2, 5, 0, 1, 6, 2, 1, 4, 2]
Acc: 45.9875
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.46172824637859533
avg_loss_weight: 
 0.5044
 0.5458
 0.7467
 0.9133
 0.7245
 0.4522
 0.3452
 0.8549
[torch.FloatTensor of size 8]

lr: 0.00031640625000000006 lr2: 0.00011250000000000001
[6,    46] loss: 1.223, acc: 54.688
[6,    92] loss: 1.241, acc: 60.938
[6,   138] loss: 1.224, acc: 51.562
[6,   184] loss: 1.234, acc: 45.312
[6,   230] loss: 1.222, acc: 60.938
[6,   276] loss: 1.251, acc: 45.312
[6,   322] loss: 1.234, acc: 57.812
[6,   368] loss: 1.225, acc: 56.250
[6,   414] loss: 1.257, acc: 54.688
[6,   460] loss: 1.215, acc: 59.375
[6,   506] loss: 1.254, acc: 53.125
[6,   552] loss: 1.224, acc: 51.562
[6,   598] loss: 1.209, acc: 56.250
[6,   644] loss: 1.251, acc: 53.125
[6,   690] loss: 1.270, acc: 64.062
[6,   736] loss: 1.231, acc: 45.312
[6,   782] loss: 1.230, acc: 56.250
[6,   828] loss: 1.242, acc: 64.062
[6,   874] loss: 1.251, acc: 54.688
[6,   920] loss: 1.236, acc: 54.688
[6,   966] loss: 1.221, acc: 54.688
[6,  1012] loss: 1.218, acc: 54.688
[6,  1058] loss: 1.250, acc: 57.812
[6,  1104] loss: 1.237, acc: 62.500
[6,  1150] loss: 1.234, acc: 48.438
[6,  1196] loss: 1.250, acc: 57.812
[6,  1242] loss: 1.211, acc: 46.875
[6,  1288] loss: 1.230, acc: 51.562
[6,  1334] loss: 1.219, acc: 60.938
[6,  1380] loss: 1.222, acc: 54.688
[6,  1426] loss: 1.250, acc: 45.312
[6,  1472] loss: 1.232, acc: 68.750
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 2, 4, 0, 1, 6, 2, 1, 4, 2]
Acc: 45.8958333333
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.46721175009390375
avg_loss_weight: 
 0.5052
 0.5495
 0.7129
 0.8970
 0.7109
 0.4751
 0.3501
 0.8378
[torch.FloatTensor of size 8]

lr: 0.00023730468750000005 lr2: 8.4375e-05
[7,    46] loss: 1.176, acc: 51.562
[7,    92] loss: 1.163, acc: 59.375
[7,   138] loss: 1.169, acc: 51.562
[7,   184] loss: 1.149, acc: 67.188
[7,   230] loss: 1.172, acc: 65.625
[7,   276] loss: 1.156, acc: 70.312
[7,   322] loss: 1.182, acc: 53.125
[7,   368] loss: 1.156, acc: 53.125
[7,   414] loss: 1.190, acc: 54.688
[7,   460] loss: 1.155, acc: 78.125
[7,   506] loss: 1.192, acc: 48.438
[7,   552] loss: 1.213, acc: 56.250
[7,   598] loss: 1.192, acc: 53.125
[7,   644] loss: 1.180, acc: 51.562
[7,   690] loss: 1.170, acc: 50.000
[7,   736] loss: 1.183, acc: 60.938
[7,   782] loss: 1.196, acc: 45.312
[7,   828] loss: 1.163, acc: 56.250
[7,   874] loss: 1.153, acc: 51.562
[7,   920] loss: 1.161, acc: 62.500
[7,   966] loss: 1.162, acc: 56.250
[7,  1012] loss: 1.181, acc: 56.250
[7,  1058] loss: 1.175, acc: 46.875
[7,  1104] loss: 1.169, acc: 64.062
[7,  1150] loss: 1.164, acc: 68.750
[7,  1196] loss: 1.168, acc: 50.000
[7,  1242] loss: 1.165, acc: 50.000
[7,  1288] loss: 1.159, acc: 60.938
[7,  1334] loss: 1.191, acc: 48.438
[7,  1380] loss: 1.167, acc: 59.375
[7,  1426] loss: 1.163, acc: 68.750
[7,  1472] loss: 1.164, acc: 64.062
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 2, 4, 0, 1, 6, 2, 1, 4, 2]
Acc: 45.2083333333
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.46058688171358386
avg_loss_weight: 
 0.5032
 0.5529
 0.6857
 0.8945
 0.7130
 0.4782
 0.3654
 0.8203
[torch.FloatTensor of size 8]

lr: 0.00017797851562500002 lr2: 6.328125e-05
[8,    46] loss: 1.112, acc: 59.375
[8,    92] loss: 1.107, acc: 56.250
[8,   138] loss: 1.095, acc: 59.375
[8,   184] loss: 1.099, acc: 54.688
[8,   230] loss: 1.118, acc: 57.812
[8,   276] loss: 1.151, acc: 70.312
[8,   322] loss: 1.123, acc: 62.500
[8,   368] loss: 1.108, acc: 60.938
[8,   414] loss: 1.107, acc: 53.125
[8,   460] loss: 1.136, acc: 51.562
[8,   506] loss: 1.111, acc: 65.625
[8,   552] loss: 1.138, acc: 54.688
[8,   598] loss: 1.093, acc: 56.250
[8,   644] loss: 1.131, acc: 53.125
[8,   690] loss: 1.126, acc: 57.812
[8,   736] loss: 1.097, acc: 65.625
[8,   782] loss: 1.133, acc: 57.812
[8,   828] loss: 1.118, acc: 53.125
[8,   874] loss: 1.096, acc: 64.062
[8,   920] loss: 1.139, acc: 67.188
[8,   966] loss: 1.094, acc: 53.125
[8,  1012] loss: 1.123, acc: 65.625
[8,  1058] loss: 1.116, acc: 62.500
[8,  1104] loss: 1.121, acc: 57.812
[8,  1150] loss: 1.155, acc: 59.375
[8,  1196] loss: 1.112, acc: 57.812
[8,  1242] loss: 1.140, acc: 53.125
[8,  1288] loss: 1.103, acc: 62.500
[8,  1334] loss: 1.123, acc: 62.500
[8,  1380] loss: 1.121, acc: 59.375
[8,  1426] loss: 1.101, acc: 65.625
[8,  1472] loss: 1.122, acc: 45.312
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 2, 4, 0, 1, 6, 2, 1, 4, 2]
Acc: 45.5208333333
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.46212686480286863
avg_loss_weight: 
 0.4981
 0.5524
 0.6846
 0.8895
 0.7137
 0.4732
 0.3726
 0.8286
[torch.FloatTensor of size 8]

lr: 0.00013348388671875002 lr2: 4.74609375e-05
[9,    46] loss: 1.063, acc: 56.250
[9,    92] loss: 1.114, acc: 48.438
[9,   138] loss: 1.082, acc: 59.375
[9,   184] loss: 1.071, acc: 62.500
[9,   230] loss: 1.065, acc: 56.250
[9,   276] loss: 1.068, acc: 67.188
[9,   322] loss: 1.060, acc: 60.938
[9,   368] loss: 1.066, acc: 65.625
[9,   414] loss: 1.086, acc: 51.562
[9,   460] loss: 1.059, acc: 65.625
[9,   506] loss: 1.057, acc: 60.938
[9,   552] loss: 1.076, acc: 57.812
[9,   598] loss: 1.083, acc: 57.812
[9,   644] loss: 1.067, acc: 53.125
[9,   690] loss: 1.074, acc: 60.938
[9,   736] loss: 1.078, acc: 56.250
[9,   782] loss: 1.053, acc: 64.062
[9,   828] loss: 1.084, acc: 60.938
[9,   874] loss: 1.091, acc: 57.812
[9,   920] loss: 1.068, acc: 75.000
[9,   966] loss: 1.081, acc: 62.500
[9,  1012] loss: 1.070, acc: 71.875
[9,  1058] loss: 1.077, acc: 68.750
[9,  1104] loss: 1.049, acc: 57.812
[9,  1150] loss: 1.072, acc: 64.062
[9,  1196] loss: 1.081, acc: 70.312
[9,  1242] loss: 1.069, acc: 62.500
[9,  1288] loss: 1.079, acc: 53.125
[9,  1334] loss: 1.069, acc: 53.125
[9,  1380] loss: 1.076, acc: 46.875
[9,  1426] loss: 1.080, acc: 53.125
[9,  1472] loss: 1.058, acc: 51.562
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 2, 4, 0, 1, 6, 2, 1, 4, 2]
Acc: 45.4458333333
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.463390245277205
avg_loss_weight: 
 0.4994
 0.5556
 0.6737
 0.8816
 0.7124
 0.4792
 0.3744
 0.8244
[torch.FloatTensor of size 8]

lr: 0.00010011291503906251 lr2: 3.5595703124999996e-05
[10,    46] loss: 1.038, acc: 62.500
[10,    92] loss: 1.018, acc: 68.750
[10,   138] loss: 1.030, acc: 56.250
[10,   184] loss: 0.987, acc: 73.438
[10,   230] loss: 1.000, acc: 60.938
[10,   276] loss: 1.053, acc: 59.375
[10,   322] loss: 1.040, acc: 53.125
[10,   368] loss: 1.044, acc: 60.938
[10,   414] loss: 1.042, acc: 70.312
[10,   460] loss: 1.036, acc: 60.938
[10,   506] loss: 1.055, acc: 56.250
[10,   552] loss: 1.035, acc: 59.375
[10,   598] loss: 1.044, acc: 60.938
[10,   644] loss: 1.041, acc: 56.250
[10,   690] loss: 1.010, acc: 60.938
[10,   736] loss: 1.049, acc: 78.125
[10,   782] loss: 1.071, acc: 67.188
[10,   828] loss: 1.047, acc: 65.625
[10,   874] loss: 1.046, acc: 68.750
[10,   920] loss: 1.056, acc: 64.062
[10,   966] loss: 1.033, acc: 62.500
[10,  1012] loss: 1.038, acc: 57.812
[10,  1058] loss: 1.014, acc: 62.500
[10,  1104] loss: 1.039, acc: 60.938
[10,  1150] loss: 1.030, acc: 68.750
[10,  1196] loss: 1.046, acc: 56.250
[10,  1242] loss: 1.034, acc: 60.938
[10,  1288] loss: 1.036, acc: 60.938
[10,  1334] loss: 1.029, acc: 60.938
[10,  1380] loss: 1.054, acc: 67.188
[10,  1426] loss: 1.022, acc: 73.438
[10,  1472] loss: 1.015, acc: 67.188
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 2, 1, 0, 1, 6, 2, 1, 4, 3]
Acc: 45.1291666667
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.4599017312859408
avg_loss_weight: 
 0.4957
 0.5613
 0.6672
 0.8769
 0.7099
 0.4842
 0.3770
 0.8202
[torch.FloatTensor of size 8]

lr: 7.508468627929689e-05 lr2: 2.6696777343749997e-05
[11,    46] loss: 1.013, acc: 57.812
[11,    92] loss: 0.995, acc: 73.438
[11,   138] loss: 1.014, acc: 60.938
[11,   184] loss: 0.994, acc: 68.750
[11,   230] loss: 0.992, acc: 59.375
[11,   276] loss: 1.002, acc: 68.750
[11,   322] loss: 1.002, acc: 62.500
[11,   368] loss: 1.000, acc: 67.188
[11,   414] loss: 1.010, acc: 51.562
[11,   460] loss: 0.980, acc: 60.938
[11,   506] loss: 1.015, acc: 62.500
[11,   552] loss: 0.987, acc: 67.188
[11,   598] loss: 1.002, acc: 68.750
[11,   644] loss: 1.006, acc: 75.000
[11,   690] loss: 1.031, acc: 53.125
[11,   736] loss: 0.994, acc: 65.625
[11,   782] loss: 1.013, acc: 57.812
[11,   828] loss: 1.047, acc: 65.625
[11,   874] loss: 0.999, acc: 57.812
[11,   920] loss: 1.011, acc: 65.625
[11,   966] loss: 0.999, acc: 73.438
[11,  1012] loss: 0.996, acc: 67.188
[11,  1058] loss: 0.997, acc: 64.062
[11,  1104] loss: 0.998, acc: 68.750
[11,  1150] loss: 0.991, acc: 64.062
[11,  1196] loss: 1.014, acc: 62.500
[11,  1242] loss: 0.998, acc: 70.312
[11,  1288] loss: 1.023, acc: 54.688
[11,  1334] loss: 1.029, acc: 59.375
[11,  1380] loss: 1.017, acc: 70.312
[11,  1426] loss: 1.016, acc: 68.750
[11,  1472] loss: 1.018, acc: 54.688
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 2, 1, 0, 1, 6, 2, 1, 4, 3]
Acc: 45.35
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.46182496726247646
avg_loss_weight: 
 0.4938
 0.5622
 0.6666
 0.8735
 0.7060
 0.4888
 0.3779
 0.8181
[torch.FloatTensor of size 8]

lr: 5.631351470947266e-05 lr2: 2.0022583007812497e-05
[12,    46] loss: 1.006, acc: 65.625
[12,    92] loss: 0.977, acc: 78.125
[12,   138] loss: 0.979, acc: 56.250
[12,   184] loss: 0.946, acc: 70.312
[12,   230] loss: 0.976, acc: 68.750
[12,   276] loss: 0.982, acc: 68.750
[12,   322] loss: 0.959, acc: 70.312
[12,   368] loss: 0.986, acc: 70.312
[12,   414] loss: 0.981, acc: 62.500
[12,   460] loss: 1.003, acc: 60.938
[12,   506] loss: 0.970, acc: 62.500
[12,   552] loss: 0.983, acc: 68.750
[12,   598] loss: 0.995, acc: 73.438
[12,   644] loss: 0.992, acc: 50.000
[12,   690] loss: 0.973, acc: 65.625
[12,   736] loss: 0.997, acc: 65.625
[12,   782] loss: 0.996, acc: 75.000
[12,   828] loss: 0.991, acc: 56.250
[12,   874] loss: 0.964, acc: 65.625
[12,   920] loss: 0.997, acc: 70.312
[12,   966] loss: 0.962, acc: 65.625
[12,  1012] loss: 0.977, acc: 53.125
[12,  1058] loss: 0.981, acc: 65.625
[12,  1104] loss: 0.964, acc: 73.438
[12,  1150] loss: 0.962, acc: 67.188
[12,  1196] loss: 0.963, acc: 62.500
[12,  1242] loss: 1.004, acc: 73.438
[12,  1288] loss: 0.963, acc: 62.500
[12,  1334] loss: 1.008, acc: 68.750
[12,  1380] loss: 0.988, acc: 68.750
[12,  1426] loss: 0.988, acc: 75.000
[12,  1472] loss: 1.013, acc: 64.062
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 2, 1, 0, 1, 6, 2, 1, 4, 3]
Acc: 45.0375
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.4602904169280146
avg_loss_weight: 
 0.4974
 0.5626
 0.6662
 0.8704
 0.6991
 0.4937
 0.3787
 0.8194
[torch.FloatTensor of size 8]

lr: 4.22351360321045e-05 lr2: 1.5016937255859373e-05
[13,    46] loss: 0.956, acc: 62.500
[13,    92] loss: 0.941, acc: 60.938
[13,   138] loss: 0.974, acc: 68.750
[13,   184] loss: 0.969, acc: 57.812
[13,   230] loss: 0.963, acc: 65.625
[13,   276] loss: 0.958, acc: 71.875
[13,   322] loss: 0.974, acc: 65.625
[13,   368] loss: 0.972, acc: 62.500
[13,   414] loss: 0.977, acc: 70.312
[13,   460] loss: 0.936, acc: 57.812
[13,   506] loss: 0.958, acc: 70.312
[13,   552] loss: 0.987, acc: 79.688
[13,   598] loss: 0.957, acc: 71.875
[13,   644] loss: 0.962, acc: 68.750
[13,   690] loss: 0.985, acc: 71.875
[13,   736] loss: 0.951, acc: 70.312
[13,   782] loss: 0.972, acc: 64.062
[13,   828] loss: 0.970, acc: 65.625
[13,   874] loss: 0.977, acc: 60.938
[13,   920] loss: 0.975, acc: 67.188
[13,   966] loss: 0.980, acc: 65.625
[13,  1012] loss: 0.957, acc: 65.625
[13,  1058] loss: 0.962, acc: 65.625
[13,  1104] loss: 0.925, acc: 67.188
[13,  1150] loss: 0.990, acc: 57.812
[13,  1196] loss: 0.962, acc: 62.500
[13,  1242] loss: 0.961, acc: 65.625
[13,  1288] loss: 0.953, acc: 59.375
[13,  1334] loss: 0.971, acc: 73.438
[13,  1380] loss: 0.979, acc: 53.125
[13,  1426] loss: 0.952, acc: 73.438
[13,  1472] loss: 0.963, acc: 57.812
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 2, 1, 0, 1, 6, 2, 1, 4, 3]
Acc: 45.1583333333
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.4613890557725261
avg_loss_weight: 
 0.4974
 0.5650
 0.6642
 0.8654
 0.6965
 0.4973
 0.3790
 0.8188
[torch.FloatTensor of size 8]

lr: 3.167635202407837e-05 lr2: 1.126270294189453e-05
[14,    46] loss: 0.948, acc: 68.750
[14,    92] loss: 0.954, acc: 65.625
[14,   138] loss: 0.969, acc: 70.312
[14,   184] loss: 0.928, acc: 68.750
[14,   230] loss: 0.946, acc: 76.562
[14,   276] loss: 0.952, acc: 62.500
[14,   322] loss: 0.957, acc: 75.000
[14,   368] loss: 0.941, acc: 65.625
[14,   414] loss: 0.918, acc: 68.750
[14,   460] loss: 0.976, acc: 73.438
[14,   506] loss: 0.956, acc: 67.188
[14,   552] loss: 0.960, acc: 62.500
[14,   598] loss: 0.955, acc: 60.938
[14,   644] loss: 0.959, acc: 65.625
[14,   690] loss: 0.931, acc: 57.812
[14,   736] loss: 0.939, acc: 65.625
[14,   782] loss: 0.967, acc: 60.938
[14,   828] loss: 0.985, acc: 67.188
[14,   874] loss: 0.956, acc: 64.062
[14,   920] loss: 0.950, acc: 67.188
[14,   966] loss: 0.962, acc: 59.375
[14,  1012] loss: 0.936, acc: 57.812
[14,  1058] loss: 0.959, acc: 75.000
[14,  1104] loss: 0.920, acc: 59.375
[14,  1150] loss: 0.933, acc: 67.188
[14,  1196] loss: 0.975, acc: 75.000
[14,  1242] loss: 0.949, acc: 60.938
[14,  1288] loss: 0.954, acc: 62.500
[14,  1334] loss: 0.978, acc: 68.750
[14,  1380] loss: 0.944, acc: 73.438
[14,  1426] loss: 0.943, acc: 67.188
[14,  1472] loss: 0.945, acc: 62.500
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 2, 1, 0, 1, 6, 2, 1, 4, 3]
Acc: 45.1583333333
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.46092916577314996
avg_loss_weight: 
 0.4951
 0.5665
 0.6627
 0.8623
 0.6938
 0.5021
 0.3796
 0.8186
[torch.FloatTensor of size 8]

lr: 2.3757264018058778e-05 lr2: 1e-05
[15,    46] loss: 0.948, acc: 70.312
[15,    92] loss: 0.956, acc: 71.875
[15,   138] loss: 0.946, acc: 71.875
[15,   184] loss: 0.962, acc: 54.688
[15,   230] loss: 0.950, acc: 67.188
[15,   276] loss: 0.948, acc: 67.188
^CProcess Process-116:
Process Process-115:
Process Process-114:
Process Process-113:
Traceback (most recent call last):
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 342, in get
    with self._rlock:
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/synchronize.py", line 96, in __enter__
    return self._semlock.__enter__()
Traceback (most recent call last):
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 342, in get
    with self._rlock:
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/synchronize.py", line 96, in __enter__
    return self._semlock.__enter__()
Traceback (most recent call last):
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 342, in get
    with self._rlock:
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/synchronize.py", line 96, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 343, in get
    res = self._reader.recv_bytes()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "train.py", line 214, in <module>
    main(args.model_id, use_element, args.is_save)
  File "train.py", line 152, in main
    loss.backward()
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/autograd/variable.py", line 156, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/autograd/__init__.py", line 98, in backward
    variables, grad_variables, retain_graph)
KeyboardInterrupt
dyhu@mit116:~/BDCI2017-MingLue$ clear
[H[Jdyhu@mit116:~/BDCI2017-MingLue$ [Kdyhu@mit116:~/BDCI2017-MingLue$ clea[K[K[K[Kexit
exit
dyhu@mit116:~/BDCI2017-MingLue/log/HAN$ dyhu@mit116:~/BDCI2017-MingLue/log/HAN$ [Kdyhu@mit116:~/BDCI2017-MingLue/log/HAN$ cd ..
dyhu@mit116:~/BDCI2017-MingLue/log$ cd ..
dyhu@mit116:~/BDCI2017-MingLue$ p[KCUDA_VISIBle[KE_DEVICES=2 python train.py --o[Kmodel-id 4 --i s-save y --use-elemetn y[1P y[1P yn yt y
Using TensorFlow backend.
loading data...
max sentence length:  42583
total vocab size 691360
load word2index
0 1
(120000, 50, 60)
data loaded
config vocab size: 194170
use element
pretrain...
Traceback (most recent call last):
  File "train.py", line 214, in <module>
    main(args.model_id, use_element, args.is_save)
  File "train.py", line 101, in main
    all_element_vector = bpe.load_pickle(config.element_vector_path)
  File "/home/dyhu/BDCI2017-MingLue/preprocessor/buildpretrainemb.py", line 11, in load_pickle
    pkl_f = open(fpath, 'rb')
FileNotFoundError: [Errno 2] No such file or directory: './pickles/sample_seg_train_element_vector.pkl'
dyhu@mit116:~/BDCI2017-MingLue$ [Kdyhu@mit116:~/BDCI2017-MingLue$ CUDA_VISIBlE_DEVICES=2 python train.py --model-id 4 --iss-save y --use-element y\[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K
Using TensorFlow backend.
loading data...
max sentence length:  42583
total vocab size 691360
load word2index
0 1
(120000, 50, 60)
data loaded
config vocab size: 194170
pretrain...
loss weight: 
 0.7786
 0.8593
 1.1661
 1.2979
 1.1405
 0.9833
 0.5955
 1.1791
[torch.FloatTensor of size 8]

training...
lr: 0.001 lr2: 0.0
Traceback (most recent call last):
  File "train.py", line 214, in <module>
    main(args.model_id, use_element, args.is_save)
  File "train.py", line 150, in main
    outputs = model(inputs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/nn/modules/module.py", line 224, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/dyhu/BDCI2017-MingLue/models/hierarchical.py", line 244, in forward
    sequence_length = x.size()[2]
IndexError: tuple index out of range
dyhu@mit116:~/BDCI2017-MingLue$ CUDA_VISIBlE_DEVICES=2 python train.py --model-id 4 --iss-save y 
Using TensorFlow backend.
loading data...
max sentence length:  42583
total vocab size 691360
load word2index
0 1
(120000, 50, 60)
data loaded
config vocab size: 194170
pretrain...
loss weight: 
 0.7786
 0.8593
 1.1661
 1.2979
 1.1405
 0.9833
 0.5955
 1.1791
[torch.FloatTensor of size 8]

training...
lr: 0.001 lr2: 0.0
Traceback (most recent call last):
  File "train.py", line 214, in <module>
    main(args.model_id, use_element, args.is_save)
  File "train.py", line 150, in main
    outputs = model(inputs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/nn/modules/module.py", line 224, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/dyhu/BDCI2017-MingLue/models/hierarchical.py", line 244, in forward
    sequence_length = x.size()[2]
IndexError: tuple index out of range
dyhu@mit116:~/BDCI2017-MingLue$ CUDA_VISIBlE_DEVICES=2 python train.py --model-id 4 --iss-save y [K[K[K[K[K[K[K[K[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K[K[K
Using TensorFlow backend.
loading data...
max sentence length:  42583
total vocab size 691360
load word2index
0 1
(120000, 50, 60)
data loaded
config vocab size: 194170
pretrain...
loss weight: 
 0.7786
 0.8593
 1.1661
 1.2979
 1.1405
 0.9833
 0.5955
 1.1791
[torch.FloatTensor of size 8]

training...
lr: 0.001 lr2: 0.0
[1,   187] loss: 1.923, acc: 25.000
[1,   374] loss: 1.781, acc: 46.875
[1,   561] loss: 1.726, acc: 34.375
[1,   748] loss: 1.701, acc: 37.500
[1,   935] loss: 1.695, acc: 46.875
[1,  1122] loss: 1.682, acc: 40.625
[1,  1309] loss: 1.637, acc: 31.250
[1,  1496] loss: 1.620, acc: 50.000
[1,  1683] loss: 1.611, acc: 43.750
[1,  1870] loss: 1.603, acc: 46.875
[1,  2057] loss: 1.600, acc: 40.625
[1,  2244] loss: 1.587, acc: 46.875
[1,  2431] loss: 1.567, acc: 34.375
[1,  2618] loss: 1.563, acc: 40.625
[1,  2805] loss: 1.570, acc: 56.250
[1,  2992] loss: 1.542, acc: 56.250
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[5, 1, 5, 0, 1, 5, 2, 2, 5, 1]
Acc: 41.35
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.39154125158021574
lr: 0.001 lr2: 0.0
[2,   187] loss: 1.520, acc: 21.875
[2,   374] loss: 1.513, acc: 31.250
[2,   561] loss: 1.535, acc: 28.125
[2,   748] loss: 1.517, acc: 43.750
[2,   935] loss: 1.531, acc: 46.875
[2,  1122] loss: 1.501, acc: 46.875
[2,  1309] loss: 1.507, acc: 56.250
[2,  1496] loss: 1.491, acc: 31.250
[2,  1683] loss: 1.502, acc: 37.500
[2,  1870] loss: 1.490, acc: 53.125
[2,  2057] loss: 1.502, acc: 46.875
[2,  2244] loss: 1.490, acc: 46.875
[2,  2431] loss: 1.486, acc: 37.500
[2,  2618] loss: 1.462, acc: 43.750
[2,  2805] loss: 1.462, acc: 46.875
[2,  2992] loss: 1.482, acc: 56.250
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[5, 2, 5, 0, 4, 6, 2, 1, 4, 2]
Acc: 44.0083333333
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.4163382180841381
lr: 0.00075 lr2: 0.0
q [3,   187] loss: 1.439, acc: 56.250
[3,   374] loss: 1.434, acc: 25.000
[3,   561] loss: 1.435, acc: 46.875
[3,   748] loss: 1.420, acc: 53.125
[3,   935] loss: 1.402, acc: 37.500
[3,  1122] loss: 1.436, acc: 53.125
[3,  1309] loss: 1.441, acc: 43.750
[3,  1496] loss: 1.408, acc: 40.625
[3,  1683] loss: 1.435, acc: 65.625
[3,  1870] loss: 1.418, acc: 43.750
[3,  2057] loss: 1.409, acc: 53.125
[3,  2244] loss: 1.405, acc: 37.500
[3,  2431] loss: 1.405, acc: 71.875
[3,  2618] loss: 1.395, acc: 50.000
[3,  2805] loss: 1.404, acc: 50.000
[3,  2992] loss: 1.410, acc: 50.000
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 2, 4, 0, 4, 5, 4, 1, 4, 1]
Acc: 45.0041666667
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.44440021176883404
lr: 0.0005625000000000001 lr2: 0.0002
[4,   187] loss: 1.347, acc: 56.250
[4,   374] loss: 1.349, acc: 53.125
[4,   561] loss: 1.357, acc: 62.500
[4,   748] loss: 1.360, acc: 46.875
[4,   935] loss: 1.359, acc: 53.125
[4,  1122] loss: 1.348, acc: 46.875
[4,  1309] loss: 1.349, acc: 53.125
[4,  1496] loss: 1.365, acc: 37.500
[4,  1683] loss: 1.350, acc: 53.125
[4,  1870] loss: 1.349, acc: 40.625
[4,  2057] loss: 1.326, acc: 50.000
[4,  2244] loss: 1.342, acc: 50.000
[4,  2431] loss: 1.349, acc: 46.875
[4,  2618] loss: 1.341, acc: 50.000
[4,  2805] loss: 1.347, acc: 46.875
[4,  2992] loss: 1.340, acc: 62.500
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 2, 1, 0, 2, 6, 4, 1, 4, 2]
Acc: 47.1916666667
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.46637084950484153
avg_loss_weight: 
 0.4952
 0.4429
 0.7372
 0.9354
 0.7673
 0.4928
 0.3052
 0.8661
[torch.FloatTensor of size 8]

lr: 0.00042187500000000005 lr2: 0.00015000000000000001
[5,   187] loss: 1.250, acc: 53.125
[5,   374] loss: 1.259, acc: 50.000
[5,   561] loss: 1.259, acc: 50.000
[5,   748] loss: 1.271, acc: 43.750
[5,   935] loss: 1.245, acc: 34.375
[5,  1122] loss: 1.232, acc: 59.375
[5,  1309] loss: 1.258, acc: 46.875
[5,  1496] loss: 1.231, acc: 46.875
[5,  1683] loss: 1.257, acc: 62.500
[5,  1870] loss: 1.238, acc: 50.000
[5,  2057] loss: 1.264, acc: 59.375
[5,  2244] loss: 1.225, acc: 37.500
[5,  2431] loss: 1.228, acc: 59.375
[5,  2618] loss: 1.255, acc: 53.125
[5,  2805] loss: 1.241, acc: 56.250
[5,  2992] loss: 1.235, acc: 56.250
predicting...
[2, 1, 1, 0, 2, 6, 6, 1, 4, 4]
[4, 2, 5, 0, 4, 6, 4, 1, 4, 2]
Acc: 48.0666666667
Counter({6: 5869, 1: 4060, 5: 3835, 2: 2999, 0: 2928, 4: 2862, 3: 1223, 7: 224})
Micro-Averaged F1: 0.4772223742937947
avg_loss_weight: 
 0.4448
 0.4823
 0.7292
 0.9080
 0.7477
 0.4973
 0.3012
 0.8772
[torch.FloatTensor of size 8]

lr: 0.00031640625000000006 lr2: 0.00011250000000000001
[6,   187] loss: 1.142, acc: 62.500
[6,   374] loss: 1.148, acc: 71.875
[6,   561] loss: 1.176, acc: 53.125
[6,   748] loss: 1.146, acc: 78.125
[6,   935] loss: 1.151, acc: 59.375
[6,  1122] loss: 1.157, acc: 65.625
[6,  1309] loss: 1.156, acc: 40.625
[6,  1496] loss: 1.134, acc: 75.000
[6,  1683] loss: 1.146, acc: 65.625
[6,  1870] loss: 1.158, acc: 56.250
[6,  2057] loss: 1.168, acc: 68.750
[6,  2244] loss: 1.175, acc: 50.000
^[[B^CProcess Process-43:
Process Process-44:
Process Process-42:
Process Process-41:
Traceback (most recent call last):
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 342, in get
    with self._rlock:
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/synchronize.py", line 96, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 342, in get
    with self._rlock:
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/synchronize.py", line 96, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 342, in get
    with self._rlock:
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/synchronize.py", line 96, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 34, in _worker_loop
    r = index_queue.get()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/queues.py", line 343, in get
    res = self._reader.recv_bytes()
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/dyhu/.pyenv/versions/3.6.1/lib/python3.6/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "train.py", line 214, in <module>
    main(args.model_id, use_element, args.is_save)
  File "train.py", line 152, in main
    loss.backward()
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/autograd/variable.py", line 156, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, retain_variables)
  File "/home/dyhu/.pyenv/versions/private/lib/python3.6/site-packages/torch/autograd/__init__.py", line 98, in backward
    variables, grad_variables, retain_graph)
KeyboardInterrupt
dyhu@mit116:~/BDCI2017-MingLue$ dyhu@mit116:/backup231/dyhu/BDCI2017-MingLue/log/HAN$ 